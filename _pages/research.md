---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

{% include base_path %}

**Audiovisual Modeling**: Developing audiovisual models in the context of human communication and interaction. My research explores how to integrate both speech and visual modalities so as to enhance the understanding of human interactions and the generation of natural facial expressions and body motions.
- [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
- [Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset.](https://arxiv.org/abs/2506.22554)
- [AV-Flow: Transforming Text to Audio-Visual Human-like Interactions.](https://arxiv.org/abs/2502.13133)

**Multimodal Language Model**: This line of research centers on language models that integrate text, speech and visual signals to advance multimodal understanding and generation. My research projects cover the modality fusion approaches and multi-task training with large-scale data to achieve the model capability of spoken dialogue generation and cross-modal translation.
- [AV-Dialog: Spoken Dialogue Models with Audio-Visual Input](https://arxiv.org/abs/2511.11124)
- [SeamlessExpressiveLM: Speech Language Model for Expressive Speech-to-Speech Translation with Chain-of-Thought.](https://arxiv.org/abs/2405.20410)
- [Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents](https://arxiv.org/abs/2409.15594)
- [Investigating Decoder-only Large Language Models for Speech-to-text Translation](https://arxiv.org/abs/2407.03169)
- [MSLM-S2ST: A Multitask Speech Language Model for Textless Speech-to-Speech Translation with Speaker Style Preservation](https://arxiv.org/abs/2403.12408)

**Cross-modal Translation**: This study addresses core challenges of translation across speech and text modalities, diving deeply into aligned data mining, massive multilinguality and multi-task training.
- [Joint Speech and Text Machine Translation for Up To 100 Languages](https://scholar.google.com/scholar?cluster=3065586836836110230&hl=en&oi=scholarr)
- [SpeechMatrix: A Large-Scale Mined Corpus of Multilingual Speech-to-Speech Translations](https://aclanthology.org/2023.acl-long.899/)
- [Pre-training for Speech Translation: CTC Meets Optimal Transport](http://proceedings.mlr.press/v202/le23a.html)
- [Multilingual Speech-to-Speech Translation into Multiple Target Languages](https://arxiv.org/abs/2307.08655)
- [T-Modules: Translation Modules for Zero-Shot Cross-Modal Machine Translation](https://aclanthology.org/2022.emnlp-main.391/)
- [Textless Speech-to-Speech Translation on Real Data](https://aclanthology.org/2022.naacl-main.63/)
- [Unified Speech-text Pre-training for Speech Translation and Recognition](https://arxiv.org/abs/2204.05409)

**Multilingual Modeling**: The explorations put emphasis on building adaptive model architectures, robust representations and scalable training recipes across diverse languages and domains.
- [Pay Better Attention to Attention: Head Selection in Multilingual and Multi-Domain Sequence Modeling](https://proceedings.neurips.cc/paper/2021/hash/15c00b5250ddedaabc203b67f8b034fd-Abstract.html)
- [Adaptive Sparse Transformer for Multilingual Translation](https://arxiv.org/abs/2104.07358)
- [Multimodal and Multilingual Embeddings for Large-Scale Speech Mining](https://proceedings.neurips.cc/paper/2021/hash/8466f9ace6a9acbe71f75762ffc890f1-Abstract.html)
- [Robust Optimization for Multilingual Translation with Imbalanced Data](https://proceedings.neurips.cc/paper/2021/hash/d324a0cc02881779dcda44a675fdcaaa-Abstract.html)

